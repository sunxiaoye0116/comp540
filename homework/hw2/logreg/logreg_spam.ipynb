{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "L2 Penalty experiments -----------\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-4.86311352] [[ -2.74146099e-02  -2.25297669e-01   1.21840891e-01   2.29362945e+00\n",
      "    2.70425725e-01   2.32851140e-01   9.28595397e-01   2.95200209e-01\n",
      "    1.62205927e-01   6.78259308e-02  -8.32603904e-02  -1.60373349e-01\n",
      "   -4.72247939e-02   1.07676991e-02   1.87903695e-01   8.19771795e-01\n",
      "    5.09529020e-01   3.98710975e-02   2.67729674e-01   3.47047342e-01\n",
      "    2.60498933e-01   3.64605628e-01   7.25019798e-01   1.96728233e-01\n",
      "   -3.15395709e+00  -4.03133841e-01  -1.25451038e+01  -6.16577226e-02\n",
      "   -1.56114586e+00  -5.51430615e-02  -3.00821906e-02   4.07263767e-01\n",
      "   -3.68156508e-01  -1.43611895e+00  -5.87181904e-01   4.44294672e-01\n",
      "    4.23159741e-02  -1.56897099e-01  -4.55330705e-01  -1.02250227e-01\n",
      "   -3.54273314e+00  -1.72944439e+00  -4.37529465e-01  -1.05999940e+00\n",
      "   -9.18599267e-01  -1.75490296e+00  -1.67475819e-01  -9.56875669e-01\n",
      "   -3.65653393e-01  -1.36535580e-01  -6.58692608e-02   2.06714067e-01\n",
      "    1.70694409e+00   1.21460293e+00  -3.35270257e-01   1.56141546e+00\n",
      "    3.68775545e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.9296875\n",
      "best_lambda =  0.6\n",
      "Coefficients =  [-4.60945018] [[-0.45145974 -0.2846657  -0.06328477  0.68295739  1.2105317   0.91504848\n",
      "   2.83046003  1.43676915  0.24145364  0.35775041 -0.38641251 -0.48142355\n",
      "  -0.69586735  0.37457213  0.64885415  1.53956261  1.38118715  0.0719795\n",
      "   0.37641708  0.63501672  0.5227532   0.38563575  2.00137913  1.50817837\n",
      "  -3.14060559 -0.6661802  -4.90648278 -0.03261144 -1.28886232 -0.15745872\n",
      "  -0.63898793 -0.30227969 -1.00990484 -0.4256814  -1.08721138  1.2843067\n",
      "  -0.90559315 -0.35285735 -1.12971262 -0.62587375 -1.40336739 -2.44122668\n",
      "  -1.55652633 -1.94778348 -1.13112577 -2.79990688 -0.75122366 -2.11600913\n",
      "  -1.68510081 -0.66772935 -0.69125269  2.06913852  4.21978004  0.76309283\n",
      "   0.70345811  0.17008795  0.43018773]]\n",
      "Accuracy on set aside test set for  logt  =  0.943359375\n",
      "best_lambda =  1.6\n",
      "Coefficients =  [-1.82566817] [[ -1.78313887e-01  -1.60085507e-01  -3.73001110e-01   2.36358803e-01\n",
      "    9.46367589e-01   1.59613651e-01   2.03690641e+00   7.62617293e-01\n",
      "    1.81159712e-01   3.12388353e-01  -2.60352275e-01  -4.14115142e-01\n",
      "   -8.66097179e-01   2.36335389e-01   4.75358416e-01   1.43030139e+00\n",
      "    8.23118667e-01  -6.18540134e-02   2.39595774e-01   4.50237962e-01\n",
      "    7.24354332e-01   1.06352180e+00   8.70212070e-01   1.30340906e+00\n",
      "   -2.20348245e+00  -4.57176450e-01  -3.39242058e+00   5.45347539e-01\n",
      "   -5.60588208e-01  -1.85244388e-01  -8.05548612e-01  -4.84223732e-01\n",
      "   -6.36751902e-01  -8.68074824e-02  -6.31860077e-01   3.04485692e-01\n",
      "   -1.03756760e+00   4.18380737e-01  -7.08628404e-01  -2.18361508e-01\n",
      "   -1.07385026e+00  -1.74862153e+00  -6.95533233e-01  -1.43004581e+00\n",
      "   -7.40200633e-01  -2.11078935e+00  -9.46977029e-02  -1.24285032e+00\n",
      "   -2.91376073e-01   1.90460650e-01  -1.65731167e-01   1.19345678e+00\n",
      "    1.42337675e+00   6.04361397e-02   7.86190381e-04   7.86190381e-04\n",
      "    7.86190381e-04]]\n",
      "Accuracy on set aside test set for  bin  =  0.928385416667\n",
      "L1 Penalty experiments -----------\n",
      "best_lambda =  4.6\n",
      "Coefficients =  [-1.58280291] [[-0.01061071 -0.15869811  0.12267091  0.20851215  0.24909835  0.17678678\n",
      "   0.91020086  0.28986022  0.13928157  0.04854966 -0.02288016 -0.13980004\n",
      "  -0.00717491  0.0092013   0.15403257  0.75699937  0.46039229  0.07050443\n",
      "   0.25416016  0.1960716   0.24308068  0.34675379  0.72782696  0.23443111\n",
      "  -2.3375166  -0.35735867 -3.13928863 -0.01066728 -0.36901613  0.          0.\n",
      "   0.         -0.32745166  0.         -0.06100601  0.24214274  0.\n",
      "  -0.11597018 -0.31112923 -0.04416669 -0.23851297 -0.79459728 -0.19040769\n",
      "  -0.56313995 -0.73419545 -1.1787904  -0.08547832 -0.51293153 -0.25647559\n",
      "  -0.13378375 -0.05689159  0.21853796  1.64931406  0.22184918  0.\n",
      "   0.64856819  0.33268952]]\n",
      "Accuracy on set aside test set for  std  =  0.921875\n",
      "best_lambda =  1.6\n",
      "Coefficients =  [-4.46327591] [[-0.34339785 -0.09563279  0.          0.12938628  1.18463219  0.69056888\n",
      "   2.91333048  1.37683502  0.          0.29514881  0.         -0.48053142\n",
      "  -0.32806469  0.10724574  0.          1.49521317  1.34894057  0.\n",
      "   0.35494406  0.19675568  0.49440528  0.34751449  1.78470483  1.3295372\n",
      "  -3.49773027 -0.2697273  -7.49428423  0.         -0.41751674  0.          0.\n",
      "   0.         -0.79148167  0.         -0.23866562  0.87192195 -0.77437864\n",
      "   0.         -0.88299943  0.         -0.30396462 -2.35513116 -0.69461911\n",
      "  -1.66136332 -1.1378897  -2.98258144  0.         -1.90112741 -1.24510542\n",
      "  -0.3034939   0.          2.01474237  5.36693387  0.          0.63684261\n",
      "   0.20179785  0.38817411]]\n",
      "Accuracy on set aside test set for  logt  =  0.944010416667\n",
      "best_lambda =  3.6\n",
      "Coefficients =  [-0.10481274] [[ 0.          0.         -0.19387979  0.          0.8656693   0.\n",
      "   2.02978998  0.63399932  0.02663967  0.21208413  0.         -0.42171638\n",
      "  -0.68101536  0.          0.          1.31594702  0.76611285  0.\n",
      "   0.11021239  0.12245536  0.63337205  0.73086176  0.62111047  1.18389132\n",
      "  -2.42479769 -0.12434332 -3.73118882  0.          0.          0.          0.\n",
      "   0.         -0.28835727  0.         -0.21942189  0.         -1.01552961\n",
      "   0.         -0.40520663  0.         -0.11563562 -1.69452903 -0.03917405\n",
      "  -1.10996019 -0.68758338 -2.21923096  0.         -1.02542936 -0.12527116\n",
      "   0.07439225  0.          1.15025838  1.50045587  0.         -0.74066044\n",
      "  -0.39635716 -0.42540133]]\n",
      "Accuracy on set aside test set for  bin  =  0.92578125\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# No modifications in this script\n",
    "# complete the functions in util.py; then run the script\n",
    "\n",
    "# load the spam data in\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,type,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print \"best_lambda = \", best_lambda\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print \"Coefficients = \", lreg.intercept_,lreg.coef_\n",
    "    predy = lreg.predict(Xt)\n",
    "    print \"Accuracy on set aside test set for \", type, \" = \", np.mean(predy==ytest)\n",
    "\n",
    "print \"L2 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print \"L1 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
